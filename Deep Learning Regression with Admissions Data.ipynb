{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import app\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow\timport keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Do extensions code below\n",
    "dataset = pd.read_csv('admissions_data.csv')\n",
    "\n",
    "dataset = dataset.drop(['Serial No.'], axis = 1)\n",
    "\n",
    "labels = dataset.iloc[:,-1]\n",
    "features = dataset.iloc[:,0:-1]\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
    "  \n",
    "numerical_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_columns = numerical_features.columns\n",
    "\n",
    "ct = ColumnTransformer([(\"only numeric\", StandardScaler(),numerical_columns)], remainder='passthrough')\n",
    "\n",
    "features_train_scaled = ct.fit_transform(features_train)\n",
    "features_test_scaled = ct.transform(features_test)\n",
    "\n",
    "features_train_scaled = pd.DataFrame(features_train_scaled, columns=features_train.columns)\n",
    "features_test_scaled = pd.DataFrame(features_test_scaled, columns=features_test.columns)\n",
    "\n",
    "def design_model(features, learning_rate):\n",
    "  my_model = Sequential()\n",
    "  input = InputLayer(input_shape = (features.shape[1], ))\n",
    "  my_model.add(input)\n",
    "  my_model.add(Dense(64, activation='relu'))\n",
    "  my_model.add(layers.Dropout(0.2))\n",
    "  my_model.add(layers.Dense(128, activation='relu'))\n",
    "  my_model.add(layers.Dropout(0.1))\n",
    "  my_model.add(layers.Dense(24, activation='relu'))\n",
    "  my_model.add(layers.Dropout(0.3))\n",
    "  my_model.add(Dense(1))\n",
    "  opt = Adam(learning_rate = learning_rate)\n",
    "  my_model.compile(loss='mse',  metrics=['mae'], optimizer=opt)\n",
    "  return my_model\n",
    "\n",
    "def fit_model(my_model, features_train, labels_tain, learning_rate, num_epochs):\n",
    "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 20)\n",
    "  \n",
    "  history = my_model.fit(features_train, labels_train, epochs=num_epochs, batch_size= 2, verbose=0, validation_split = 0.2, callbacks = [es])\n",
    "  return history\n",
    "\n",
    "def fig(history):\n",
    "    # plot learning curves\n",
    "  fig = plt.figure()\n",
    "  ax1 = fig.add_subplot(2, 1, 1)\n",
    "  ax1.plot(history.history['mae'])\n",
    "  ax1.plot(history.history['val_mae'])\n",
    "  ax1.set_title('model mae')\n",
    "  ax1.set_ylabel('MAE')\n",
    "  ax1.set_xlabel('epoch')\n",
    "  ax1.legend(['train', 'validation'], loc='upper left')\n",
    "  \n",
    "    # Plot loss and val_loss over each epoch\n",
    "  ax2 = fig.add_subplot(2, 1, 2)\n",
    "  ax2.plot(history.history['loss'])\n",
    "  ax2.plot(history.history['val_loss'])\n",
    "  ax2.set_title('model loss')\n",
    "  ax2.set_ylabel('loss')\n",
    "  ax2.set_xlabel('epoch')\n",
    "  ax2.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_epochs = 40\n",
    "\n",
    "print(\"Results of model:\")\n",
    "history = fit_model(design_model(features_train, learning_rate), features_train, labels_train, learning_rate, num_epochs)\n",
    "\n",
    "# print(my_model.summary())\n",
    "# val_mse, val_mae = Sequential.evaluate(my_model)\n",
    "# val_mse, val_mae = my_model.evaluate(features_train, labels_train, verbose=0)\n",
    "my_model = design_model(features_train, learning_rate)\n",
    "mse, mae = my_model.evaluate(features_train, labels_train, verbose=1)\n",
    "val_mse, val_mae = my_model.evaluate(features_test, labels_test, verbose=0)\n",
    "predicted_values = my_model.predict(features_test) \n",
    "\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regr.fit(features_train, labels_train)\n",
    "y_pred = dummy_regr.predict(features_test)\n",
    "MAE_baseline = mean_absolute_error(labels_test, y_pred)\n",
    "\n",
    "print(\"MSE: \", val_mse)\n",
    "print(\"MAE: \", val_mae)\n",
    "print(\"R SQUARED: \", r2_score(labels_test, predicted_values))\n",
    "print(\"MEAN: \", MAE_baseline)\n",
    "# print(val_mse, val_mae)\n",
    "# my_model = design_model(features_train_scaled)\n",
    "# print(my_model.summary())\n",
    "# print(val_mse, val_mae)\n",
    "\n",
    "# print(features_train_scaled.describe())\n",
    "# print(features_test_scaled.describe())\n",
    "# print(dataset.head())\n",
    "# if you decide to do the Matplotlib extension, you must save your plot in the directory by uncommenting the line of code below\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('static/images/my_plots.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
